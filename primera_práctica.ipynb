{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/100495982/ML_G84_Grupo2/blob/main/primera_pr%C3%A1ctica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Primera Práctica**"
   ],
   "metadata": {
    "id": "ThW_dhuY2gQ3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Autores:**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Luis Enrique Valero Montero - Gr. 85 - 100495982\n",
    "\n",
    "Isabelle Borgstedt - Gr. 84 - 100559990"
   ],
   "metadata": {
    "id": "4OVWfX6uOny0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDA Simplificado"
   ],
   "metadata": {
    "id": "auHM9OFj2yoi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Things to add to the EDA:\n",
    "- Distribution graphs\n",
    "- Outlier detection and analysis\n",
    "- Covariance\n",
    "- Median, min, max, and average of important attributes\n",
    "\n",
    "We can always keep adding more to this later."
   ],
   "metadata": {
    "id": "5M_KzDhv1Ea-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKoHYwKEyYyj",
    "outputId": "b728301c-a39e-400f-db01-bbd5f8ddd065"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hay 2940 instancias y 31 variables.\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Variables categóricas:  ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'Attrition']\n",
      "Variables ordinales:  ['JobInvolvement', 'PerformanceRating', 'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance', 'Education', 'EmployeeCount', 'JobLevel', 'StandardHours', 'StockOptionLevel']\n",
      "Variables numéricas:  ['hrs', 'absences', 'Age', 'DistanceFromHome', 'EmployeeID', 'MonthlyIncome', 'NumCompaniesWorked', 'PercentSalaryHike', 'TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Variables con alta cardinalidad: \n",
      "         Variable  Unique Values\n",
      "4         JobRole              9\n",
      "2  EducationField              6\n",
      "1      Department              3\n",
      "0  BusinessTravel              3\n",
      "5   MaritalStatus              3\n",
      "3          Gender              2\n",
      "7       Attrition              2\n",
      "6          Over18              1\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Variables con valores faltantes: \n",
      "                 Variable:  Valores faltantes:  Porcentaje faltantes:\n",
      "2          WorkLifeBalance                  29               0.986395\n",
      "0  EnvironmentSatisfaction                  17               0.578231\n",
      "1          JobSatisfaction                  12               0.408163\n",
      "3       NumCompaniesWorked                  10               0.340136\n",
      "4        TotalWorkingYears                   5               0.170068\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Columnas constantes:  ['EmployeeCount', 'Over18', 'StandardHours']\n",
      "Columnas de ID:  ['EmployeeID']\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Se trata de un problema de clasificación porque el attributo'Attrition' tiene dos posibles valores categoricos discretos: Sí o No.\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Attrition\n",
      "No     0.838776\n",
      "Yes    0.161224\n",
      "Name: proportion, dtype: float64\n",
      "Está desbalanceado.\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Estadísticas descriptivas para las variables numéricas:\n",
      "+-------------------------+--------+----------+----------+---------+---------+---------+---------+----------+\n",
      "|        Variable         | count  |   mean   |   std    |   min   |   25%   |   50%   |   75%   |   max    |\n",
      "+-------------------------+--------+----------+----------+---------+---------+---------+---------+----------+\n",
      "|           hrs           | 2940.0 |   7.32   |   1.32   |  5.42   |  6.29   |  7.02   |   7.9   |  10.91   |\n",
      "|        absences         | 2940.0 |  12.81   |   5.48   |   1.0   |   8.0   |  13.0   |  17.0   |   24.0   |\n",
      "|           Age           | 2940.0 |  37.01   |   9.19   |  18.0   |  30.0   |  36.0   |  43.0   |   60.0   |\n",
      "|    DistanceFromHome     | 2940.0 |   9.23   |   8.11   |   1.0   |   2.0   |   7.0   |  14.0   |   29.0   |\n",
      "|       EmployeeID        | 2940.0 | 2229.38  | 1278.61  |   1.0   | 1113.75 | 2237.0  | 3340.25 |  4410.0  |\n",
      "|      MonthlyIncome      | 2940.0 | 65860.96 | 47453.16 | 10090.0 | 29360.0 | 50045.0 | 85780.0 | 199990.0 |\n",
      "|   NumCompaniesWorked    | 2930.0 |   2.69   |   2.52   |   0.0   |   1.0   |   2.0   |   4.0   |   9.0    |\n",
      "|    PercentSalaryHike    | 2940.0 |   15.2   |   3.65   |  11.0   |  12.0   |  14.0   |  18.0   |   25.0   |\n",
      "|    TotalWorkingYears    | 2935.0 |  11.39   |   7.88   |   0.0   |   6.0   |  10.0   |  16.0   |   40.0   |\n",
      "|  TrainingTimesLastYear  | 2940.0 |   2.81   |   1.29   |   0.0   |   2.0   |   3.0   |   3.0   |   6.0    |\n",
      "|     YearsAtCompany      | 2940.0 |   7.07   |   6.14   |   0.0   |   3.0   |   5.0   |  10.0   |   37.0   |\n",
      "| YearsSinceLastPromotion | 2940.0 |   2.26   |   3.3    |   0.0   |   0.0   |   1.0   |   3.0   |   15.0   |\n",
      "|  YearsWithCurrManager   | 2940.0 |   4.14   |   3.62   |   0.0   |   2.0   |   3.0   |   7.0   |   17.0   |\n",
      "+-------------------------+--------+----------+----------+---------+---------+---------+---------+----------+\n",
      "Análisis descriptivo para las variables categóricas:\n",
      "\n",
      "Distribución de BusinessTravel:\n",
      "+-------------------+------------+\n",
      "|  BusinessTravel   | Percentage |\n",
      "+-------------------+------------+\n",
      "|   Travel_Rarely   |   71.63    |\n",
      "| Travel_Frequently |   18.37    |\n",
      "|    Non-Travel     |    10.0    |\n",
      "+-------------------+------------+\n",
      "\n",
      "Distribución de Department:\n",
      "+------------------------+------------+\n",
      "|       Department       | Percentage |\n",
      "+------------------------+------------+\n",
      "| Research & Development |   64.52    |\n",
      "|         Sales          |   31.12    |\n",
      "|    Human Resources     |    4.35    |\n",
      "+------------------------+------------+\n",
      "\n",
      "Distribución de EducationField:\n",
      "+------------------+------------+\n",
      "|  EducationField  | Percentage |\n",
      "+------------------+------------+\n",
      "|  Life Sciences   |   41.36    |\n",
      "|     Medical      |   30.34    |\n",
      "|    Marketing     |   11.29    |\n",
      "| Technical Degree |    9.32    |\n",
      "|      Other       |    5.85    |\n",
      "| Human Resources  |    1.84    |\n",
      "+------------------+------------+\n",
      "\n",
      "Distribución de Gender:\n",
      "+--------+------------+\n",
      "| Gender | Percentage |\n",
      "+--------+------------+\n",
      "|  Male  |   60.44    |\n",
      "| Female |   39.56    |\n",
      "+--------+------------+\n",
      "\n",
      "Distribución de JobRole:\n",
      "+---------------------------+------------+\n",
      "|          JobRole          | Percentage |\n",
      "+---------------------------+------------+\n",
      "|      Sales Executive      |   21.97    |\n",
      "|    Research Scientist     |   20.48    |\n",
      "|   Laboratory Technician   |   17.55    |\n",
      "|  Manufacturing Director   |   10.24    |\n",
      "| Healthcare Representative |    9.15    |\n",
      "|          Manager          |    6.53    |\n",
      "|   Sales Representative    |    5.58    |\n",
      "|     Research Director     |    5.41    |\n",
      "|      Human Resources      |    3.1     |\n",
      "+---------------------------+------------+\n",
      "\n",
      "Distribución de MaritalStatus:\n",
      "+---------------+------------+\n",
      "| MaritalStatus | Percentage |\n",
      "+---------------+------------+\n",
      "|    Married    |   45.75    |\n",
      "|    Single     |   32.14    |\n",
      "|   Divorced    |   22.11    |\n",
      "+---------------+------------+\n",
      "\n",
      "Distribución de Over18:\n",
      "+--------+------------+\n",
      "| Over18 | Percentage |\n",
      "+--------+------------+\n",
      "|   Y    |   100.0    |\n",
      "+--------+------------+\n",
      "\n",
      "Distribución de Attrition:\n",
      "+-----------+------------+\n",
      "| Attrition | Percentage |\n",
      "+-----------+------------+\n",
      "|    No     |   83.88    |\n",
      "|    Yes    |   16.12    |\n",
      "+-----------+------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "df = pd.read_csv(\"attrition_availabledata_09.csv\")\n",
    "\n",
    "# ¿Cuántas variables e instancias hay?\n",
    "print(\"Hay \" + str(df.shape[0]) + \" instancias y \" + str(df.shape[1]) + \" variables.\")\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# ¿Qué variables son categóricas/ordinales/númericas?\n",
    "cat_var = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "def ordinales_o_numericas(df, threshold=5):\n",
    "  num_var = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "  ord_var = []\n",
    "\n",
    "  for col in num_var:\n",
    "    unique_values = df[col].nunique()\n",
    "    if unique_values <= threshold:\n",
    "      ord_var.append(col)\n",
    "    num_var = [x for x in num_var if x not in ord_var]\n",
    "  return num_var, ord_var\n",
    "\n",
    "print(\"Variables categóricas: \", cat_var)\n",
    "print(\"Variables ordinales: \", ordinales_o_numericas(df)[1])\n",
    "print(\"Variables numéricas: \", ordinales_o_numericas(df)[0])\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "#corr_matrix = df.corr()\n",
    "#print(\"Matriz de correlación: \")\n",
    "#print(corr_matrix)\n",
    "#print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "# ¿Hay variables categóricas con alta cardinalidad?\n",
    "def cardinalidad(df):\n",
    "  cat_var = df.select_dtypes(include=['object']).columns.tolist()\n",
    "  cardinalidad = {col: df[col].nunique() for col in cat_var}\n",
    "  cardinalidad_df = pd.DataFrame(list(cardinalidad.items()), columns=['Variable', 'Unique Values'])\n",
    "  cardinalidad_df = cardinalidad_df.sort_values(by=\"Unique Values\", ascending=False)\n",
    "  return cardinalidad_df\n",
    "\n",
    "print(\"Variables con alta cardinalidad: \")\n",
    "cardinalidad_df = cardinalidad(df)\n",
    "print(cardinalidad_df)\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "# ¿Qué variables tienen valores faltantes y cuántos?\n",
    "def faltantes(df):\n",
    "  datos_faltantes = df.isnull().sum()\n",
    "  datos_faltantes = datos_faltantes[datos_faltantes > 0]\n",
    "  faltantes_df = pd.DataFrame({\n",
    "      \"Variable:\": datos_faltantes.index,\n",
    "      \"Valores faltantes:\": datos_faltantes.values,\n",
    "      \"Porcentaje faltantes:\": datos_faltantes.values / len(df) * 100\n",
    "  })\n",
    "  faltantes_df = faltantes_df.sort_values(by=\"Porcentaje faltantes:\", ascending=False)\n",
    "  return faltantes_df\n",
    "\n",
    "print(\"Variables con valores faltantes: \")\n",
    "faltantes_df = faltantes(df)\n",
    "print(faltantes_df)\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# ¿Hay columnas constantes o columnas de ID?\n",
    "def constantes(df):\n",
    "  constantes = []\n",
    "  for col in df.columns:\n",
    "    if df[col].nunique() == 1:\n",
    "      constantes.append(col)\n",
    "  return constantes\n",
    "\n",
    "print(\"Columnas constantes: \", constantes(df))\n",
    "\n",
    "def id(df):\n",
    "  id_cols = []\n",
    "  for col in df.columns:\n",
    "    if df[col].nunique() == len(df):\n",
    "      id_cols.append(col)\n",
    "  return id_cols\n",
    "\n",
    "print(\"Columnas de ID: \", id(df))\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "# ¿Se trata de un problema de regresión o clasificación?\n",
    "print(\"Se trata de un problema de clasificación porque el attributo'Attrition' tiene dos posibles valores categoricos discretos: Sí o No.\")\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "# Si es clasificación, ¿está desbalanceado?\n",
    "print(df[\"Attrition\"].value_counts(normalize=True))\n",
    "print(\"Está desbalanceado.\")\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "# Definir variables numéricas\n",
    "numerical_vars, ordinal_vars = ordinales_o_numericas(df)\n",
    "\n",
    "print(\"Estadísticas descriptivas para las variables numéricas:\")\n",
    "df_num_desc = df[numerical_vars].describe().transpose().round(2)  # Transpose for readability & round to 2 decimals\n",
    "df_num_desc.insert(0, \"Variable\", df_num_desc.index)  # Add column for variable names\n",
    "print(tabulate(df_num_desc, headers='keys', tablefmt='pretty', showindex=False))  # Print as a formatted table\n",
    "\n",
    "\n",
    "print(\"Análisis descriptivo para las variables categóricas:\")\n",
    "for col in cat_var:\n",
    "    print(f\"\\nDistribución de {col}:\")\n",
    "    df_cat = df[col].value_counts(normalize=True).mul(100).round(2).reset_index()  # Round to 2 decimal places\n",
    "    df_cat.columns = [col, 'Percentage']\n",
    "    print(tabulate(df_cat, headers='keys', tablefmt='pretty', showindex=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos a encontrar \"outliers\" para determinar las mejores opciones para escalado y imputación."
   ],
   "metadata": {
    "id": "4ka_DA1-DW3H"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Detecting Outliers using Z-Score\n",
    "def zscore_outliers(df, threshold=3):\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    outliers_list = []  # Store outliers in a list\n",
    "\n",
    "    for col in numerical_cols:\n",
    "        z_scores = zscore(df[col].dropna())  # Calculate Z-scores\n",
    "        outlier_indices = np.where(np.abs(z_scores) > threshold)[0]\n",
    "        outlier_values = df[col].iloc[outlier_indices]\n",
    "        for idx, value in zip(outlier_indices, outlier_values):\n",
    "            outliers_list.append({\"Column\": col, \"Outlier Index\": idx, \"Z-Score\": z_scores[idx]})\n",
    "\n",
    "    outliers = pd.DataFrame(outliers_list)\n",
    "    return outliers\n",
    "\n",
    "# Detecting Outliers using IQR (Interquartile Range)\n",
    "def iqr_outliers(df):\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    outliers_list = []  # Store outliers in a list\n",
    "\n",
    "    for col in numerical_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outlier_indices = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index\n",
    "        outlier_values = df[col].loc[outlier_indices]\n",
    "\n",
    "        for idx, value in zip(outlier_indices, outlier_values):\n",
    "            outliers_list.append({\"Column\": col, \"Outlier Index\": idx, \"IQR Method\": value})\n",
    "\n",
    "    outliers = pd.DataFrame(outliers_list)\n",
    "    return outliers\n",
    "\n",
    "# Find outliers using Z-Score\n",
    "outliers_zscore = zscore_outliers(df)\n",
    "print(\"\\nOutliers using Z-Score:\")\n",
    "print(outliers_zscore)\n",
    "\n",
    "# Find outliers using IQR Method\n",
    "outliers_iqr = iqr_outliers(df)\n",
    "print(\"\\nOutliers using IQR Method:\")\n",
    "print(outliers_iqr)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xrY_pNyvDrnq",
    "outputId": "d89a115b-24f2-46eb-fdf0-3f1a1084042e"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Outliers using Z-Score:\n",
      "                   Column  Outlier Index   Z-Score\n",
      "0       TotalWorkingYears             50  3.248904\n",
      "1       TotalWorkingYears            185  3.122043\n",
      "2       TotalWorkingYears            248  3.122043\n",
      "3       TotalWorkingYears            292  3.122043\n",
      "4       TotalWorkingYears            386  3.122043\n",
      "..                    ...            ...       ...\n",
      "168  YearsWithCurrManager           2293  3.554717\n",
      "169  YearsWithCurrManager           2414  3.554717\n",
      "170  YearsWithCurrManager           2424  3.554717\n",
      "171  YearsWithCurrManager           2583  3.001849\n",
      "172  YearsWithCurrManager           2731  3.001849\n",
      "\n",
      "[173 rows x 3 columns]\n",
      "\n",
      "Outliers using IQR Method:\n",
      "                    Column  Outlier Index  IQR Method\n",
      "0                      hrs             12   10.666170\n",
      "1                      hrs             25   10.389476\n",
      "2                      hrs             51   10.433987\n",
      "3                      hrs             64   10.907255\n",
      "4                      hrs            214   10.711529\n",
      "...                    ...            ...         ...\n",
      "1970  YearsWithCurrManager           2293   17.000000\n",
      "1971  YearsWithCurrManager           2414   17.000000\n",
      "1972  YearsWithCurrManager           2424   17.000000\n",
      "1973  YearsWithCurrManager           2583   15.000000\n",
      "1974  YearsWithCurrManager           2731   15.000000\n",
      "\n",
      "[1975 rows x 3 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preproceso"
   ],
   "metadata": {
    "id": "EDel5QMy1ZDz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Quitar los parámetros constantes y únicos\n",
    "constantes_cols = constantes(df)\n",
    "id_cols = id(df)\n",
    "\n",
    "# Combinar las columnas para dejar y dejarlas\n",
    "columns_to_drop = constantes_cols + id_cols\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Imprimir las columnas que se quedan\n",
    "print(\"Remaining columns: \", df.columns)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgmI9cM51cXB",
    "outputId": "4a27f18c-6ba5-40cd-decd-154091d9a619"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Remaining columns:  Index(['hrs', 'absences', 'JobInvolvement', 'PerformanceRating',\n",
      "       'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance', 'Age',\n",
      "       'BusinessTravel', 'Department', 'DistanceFromHome', 'Education',\n",
      "       'EducationField', 'Gender', 'JobLevel', 'JobRole', 'MaritalStatus',\n",
      "       'MonthlyIncome', 'NumCompaniesWorked', 'PercentSalaryHike',\n",
      "       'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',\n",
      "       'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager',\n",
      "       'Attrition'],\n",
      "      dtype='object')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluacion de Rendimiento Futuro"
   ],
   "metadata": {
    "id": "KySFM-bAP91i"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aquí estamos separando los datos con Holdout: 2/3 train y 1/3 test. Debemos garantizar que los datos para \"test\" solo son usados para el rendimiento final.\n",
    "\n",
    "Es importante que mantengamos el balance cuando dividimos los datos: 83.9% \"no\" y 16.1% \"yes\"."
   ],
   "metadata": {
    "id": "XXAiXNhb4z5O"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Defining target variable and features\n",
    "target = \"Attrition\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Convert categorical variables into numerical values using One-Hot Encoding\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)  # Avoids multicollinearity by dropping one category per feature\n",
    "\n",
    "# Perform the outer train-test split (stratify to maintain class proportions)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=1/3, stratify=y, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "\n",
    "# Evaluation Function (defined but not used yet)\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates a model using Balanced Accuracy, TPR, TNR, and a confusion matrix.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)  # Get predictions\n",
    "\n",
    "    # Compute metrics\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    overall_acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Extract TPR (Sensitivity) and TNR (Specificity)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    tpr = tp / (tp + fn)  # Sensitivity (Recall for positive class)\n",
    "    tnr = tn / (tn + fp)  # Specificity\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "    print(f\"Overall Accuracy: {overall_acc:.4f}\")\n",
    "    print(f\"True Positive Rate (TPR): {tpr:.4f}\")\n",
    "    print(f\"True Negative Rate (TNR): {tnr:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "id": "tfuFQU2rvbVD",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "89bf90bc-a113-40f2-aa7a-89a010db1a4e"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training set: (1960, 40), Test set: (980, 40)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metodos Basicos: KNN y Trees"
   ],
   "metadata": {
    "id": "r-JuZ6nVQItZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "KNN:"
   ],
   "metadata": {
    "id": "g6kQi6GX4-kW"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Trees:"
   ],
   "metadata": {
    "id": "5tMl8K114VZ-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Métodos de escalado y imputación:"
   ],
   "metadata": {
    "id": "l-vOIVr1FHte"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imputación\n",
    "num_imputer = SimpleImputer(strategy=\"median\")  # Mediana porque tenemos outliers\n",
    "X_encoded.iloc[:, :] = num_imputer.fit_transform(X_encoded)\n",
    "\n",
    "# Escalado\n",
    "scaler = RobustScaler()  # Robust porque tenemos outliers\n",
    "X_scaled = scaler.fit_transform(X_encoded)\n",
    "\n",
    "# Convertirse en DataFrame después del escalado\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X_encoded.columns)\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=1/3, stratify=y, random_state=42)\n",
    "\n",
    "# Entrenar el árbol\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluarlo\n",
    "evaluate_model(model, X_test, y_test)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPRgfwwmEv4s",
    "outputId": "767304ee-4e20-4667-8313-a3f68705b104"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Balanced Accuracy: 0.7903\n",
      "Overall Accuracy: 0.8755\n",
      "True Positive Rate (TPR): 0.6646\n",
      "True Negative Rate (TNR): 0.9161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[753  69]\n",
      " [ 53 105]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.93      0.92      0.93       822\n",
      "         Yes       0.60      0.66      0.63       158\n",
      "\n",
      "    accuracy                           0.88       980\n",
      "   macro avg       0.77      0.79      0.78       980\n",
      "weighted avg       0.88      0.88      0.88       980\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Esta matrix de confusión muestra \"overall accuracy\" TPR y TNR. Es claro que \"overall accuracy\" es engañoso en este caso porque tenemos datos desbalanceados. Sin embargo, podemos ver que \"balanced accuracy\" provee una una fórmula más representativa porque da el mismo peso a los dos categorías de \"attrition\". Podemos notar la diferencia entre los porcentajes de TPR y TNR. Los datos demuestran que el rendimiento del modelo es mucho mejor para los casos de \"No\" que los casos de \"Yes\".\n",
    "\n"
   ],
   "metadata": {
    "id": "vwCPS5j242qu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modelos Lineales y SVMs"
   ],
   "metadata": {
    "id": "0PMA8CkJQOQm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Resultados y Modelo Final"
   ],
   "metadata": {
    "id": "8t7a13BvQUJa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tarea de Eleccion Abierta"
   ],
   "metadata": {
    "id": "7GcRB1iaQZhd"
   }
  }
 ]
}
